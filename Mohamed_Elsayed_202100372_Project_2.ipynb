{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgA3KZeW5cXR"
      },
      "source": [
        "# Project#2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBcvy55Xz3_T"
      },
      "source": [
        "Using only NumPy and Pandas create a Neural Network from scratch(90 pt)\n",
        "<br> Set network architecture as follows:\n",
        "* Implement input, hidden, and output layers concerning input-output shape.\n",
        "* Define activation function.\n",
        "* Implement FeedForward\n",
        "* Implement BackPropagation\n",
        "* Implement Train and Test functions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpL3HWZY0v1P"
      },
      "source": [
        "Test your model on both datasets then calculate the confusion matrix and accuracy (10 pt)\n",
        "* IRIS dataset\n",
        "* MNIST Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duch-dY34OJ0"
      },
      "source": [
        "# Bonus( 5 pt)\n",
        "1- Compare your model with the Sklearn neural network https://scikit-learn.org/stable/modules/neural_networks_supervised.html#.\n",
        "\n",
        "2- Compare your model with the Keras neural network model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import needed packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "EMoz8-T-zluV"
      },
      "outputs": [],
      "source": [
        "#importing neeeded libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Neural Network Architicture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "#implementing the neural network\n",
        "\n",
        "class NN:\n",
        "    \"\"\"\n",
        "    Neural Network class that represents a feedforward neural network.\n",
        "\n",
        "    Attributes:\n",
        "    - layers: List of layers in the neural network.\n",
        "    - parameters: Dictionary of parameters (weights and biases) for each layer.\n",
        "    - grads: Dictionary of gradients for each layer.\n",
        "    - forward_caches: Dictionary of intermediate values during forward propagation.\n",
        "\n",
        "    Methods:\n",
        "    - add(layer): Adds a layer to the neural network.\n",
        "    - _add_first_layer(layer): Adds the first layer to the neural network.\n",
        "    - _add_subsequent_layer(layer): Adds a subsequent layer to the neural network.\n",
        "    - forward_prop(X): Performs forward propagation on the input X.\n",
        "    - back_prop(Y, alpha): Performs back propagation to update the parameters.\n",
        "    - _compute_delta(l, activation): Computes the delta for a given layer during back propagation.\n",
        "    - _update_parameters(alpha): Updates the parameters (weights and biases) using the computed gradients.\n",
        "    - fit(X, y, epoch, learning_rate, multiclass=False): Trains the neural network on the input data.\n",
        "    - predict(X): Performs forward propagation to make predictions on the input X.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.parameters = {}\n",
        "        self.grads = {}\n",
        "        self.forward_caches = {}\n",
        "\n",
        "    def add(self, layer):\n",
        "        \"\"\"\n",
        "        Adds a layer to the neural network.\n",
        "\n",
        "        Args:\n",
        "        - layer: The layer to be added.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If the input shape is not specified for the first layer.\n",
        "        \"\"\"\n",
        "        if not self.layers:\n",
        "            if layer.input_shape is None:\n",
        "                raise ValueError(\"Specify input shape (number of features)\")\n",
        "            self._add_first_layer(layer)\n",
        "        else:\n",
        "            self._add_subsequent_layer(layer)\n",
        "\n",
        "    def _add_first_layer(self, layer):\n",
        "        \"\"\"\n",
        "        Adds the first layer to the neural network.\n",
        "\n",
        "        Args:\n",
        "        - layer: The first layer to be added.\n",
        "        \"\"\"\n",
        "        self.layers.append(layer)\n",
        "        layer.initialize_weights()\n",
        "        self.parameters['W1'] = layer.W\n",
        "        self.parameters['b1'] = layer.bias\n",
        "\n",
        "    def _add_subsequent_layer(self, layer):\n",
        "        \"\"\"\n",
        "        Adds a subsequent layer to the neural network.\n",
        "\n",
        "        Args:\n",
        "        - layer: The subsequent layer to be added.\n",
        "\n",
        "        Raises:\n",
        "        - ValueError: If the input shape of the subsequent layer does not match the output shape of the previous layer.\n",
        "        \"\"\"\n",
        "        prev_length = self.layers[-1].length\n",
        "        layer.set_input_shape(prev_length)\n",
        "        self.layers.append(layer)\n",
        "        layer.initialize_weights()\n",
        "        t = len(self.layers)\n",
        "        self.parameters[f'W{t}'] = layer.W\n",
        "        self.parameters[f'b{t}'] = layer.bias\n",
        "\n",
        "    def forward_prop(self, X):\n",
        "        \"\"\"\n",
        "        Performs forward propagation on the input X.\n",
        "\n",
        "        Args:\n",
        "        - X: The input data.\n",
        "\n",
        "        Updates the forward_caches dictionary with intermediate values during forward propagation.\n",
        "        \"\"\"\n",
        "        self.forward_caches['A0'] = X\n",
        "        for i, layer in enumerate(self.layers, start=1):\n",
        "            activation = layer.activation_function\n",
        "            Z = np.dot(self.forward_caches[f'A{i-1}'], self.parameters[f'W{i}']) + self.parameters[f'b{i}']\n",
        "            A = activation_functions(activation, Z)\n",
        "            self.forward_caches[f'Z{i}'] = Z\n",
        "            self.forward_caches[f'A{i}'] = A\n",
        "\n",
        "    def back_prop(self, Y, alpha):\n",
        "        \"\"\"\n",
        "        Performs back propagation to update the parameters.\n",
        "\n",
        "        Args:\n",
        "        - Y: The target output.\n",
        "        - alpha: The learning rate.\n",
        "\n",
        "        Updates the grads dictionary with gradients for each layer.\n",
        "        \"\"\"\n",
        "        L = len(self.layers)\n",
        "        AL = self.forward_caches[f'A{L}']\n",
        "        self.grads[f'delta{L}'] = (Y - AL) * back_sigmoid(AL)\n",
        "\n",
        "        for l in reversed(range(1, L)):\n",
        "            activation = self.layers[l - 1].activation_function\n",
        "            self._compute_delta(l, activation)\n",
        "\n",
        "        self._update_parameters(alpha)\n",
        "        self.grads = {}\n",
        "        self.forward_caches = {}\n",
        "\n",
        "    def _compute_delta(self, l, activation):\n",
        "        \"\"\"\n",
        "        Computes the delta for a given layer during back propagation.\n",
        "\n",
        "        Args:\n",
        "        - l: The layer index.\n",
        "        - activation: The activation function of the layer.\n",
        "        \"\"\"\n",
        "        if activation == 'sigmoid':\n",
        "            self.grads[f'delta{l}'] = np.dot(self.grads[f'delta{l+1}'], self.parameters[f'W{l+1}'].T) * back_sigmoid(self.forward_caches[f'A{l}'])\n",
        "        else:\n",
        "            self.grads[f'delta{l}'] = np.dot(self.grads[f'delta{l+1}'], self.parameters[f'W{l+1}'].T) * back_relu(self.forward_caches[f'Z{l}'])\n",
        "\n",
        "    def _update_parameters(self, alpha):\n",
        "        \"\"\"\n",
        "        Updates the parameters (weights and biases) using the computed gradients.\n",
        "\n",
        "        Args:\n",
        "        - alpha: The learning rate.\n",
        "        \"\"\"\n",
        "        for i in range(1, len(self.layers) + 1):\n",
        "            self.parameters[f'W{i}'] += np.dot(self.forward_caches[f'A{i-1}'].T, self.grads[f'delta{i}']) * alpha\n",
        "            self.parameters[f'b{i}'] += np.sum(self.grads[f'delta{i}'], axis=0, keepdims=True) * alpha\n",
        "\n",
        "    def fit(self, X, y, epoch, learning_rate, multiclass=False):\n",
        "        \"\"\"\n",
        "        Trains the neural network on the input data.\n",
        "\n",
        "        Args:\n",
        "        - X: The input data.\n",
        "        - y: The target output.\n",
        "        - epoch: The number of training epochs.\n",
        "        - learning_rate: The learning rate.\n",
        "        - multiclass: Whether the problem is a multiclass classification problem.\n",
        "\n",
        "        Prints the iteration number every 100 epochs.\n",
        "        \"\"\"\n",
        "        cost_history = []\n",
        "        for i in range(epoch):\n",
        "            self.forward_prop(X)\n",
        "            self.back_prop(y, learning_rate)\n",
        "            # if i % 100 == 0 or i == epoch - 1:\n",
        "            #     print(f'Iteration {i}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Performs forward propagation to make predictions on the input X.\n",
        "\n",
        "        Args:\n",
        "        - X: The input data.\n",
        "\n",
        "        Returns:\n",
        "        - The predicted output.\n",
        "        \"\"\"\n",
        "        self.forward_prop(X)\n",
        "        return self.forward_caches[f'A{len(self.layers)}']\n",
        "\n",
        "class Layer:\n",
        "    def __init__(self, input_shape=None, length=1, activation_function='relu'):\n",
        "        \"\"\"\n",
        "        Initializes a Layer object.\n",
        "\n",
        "        Parameters:\n",
        "        - input_shape (int): The shape of the input data. Default is None.\n",
        "        - length (int): The number of neurons in the layer. Default is 1.\n",
        "        - activation_function (str): The activation function to be used in the layer. Default is 'relu'.\n",
        "        \"\"\"\n",
        "        self.length = length\n",
        "        self.activation_function = activation_function\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        \"\"\"\n",
        "        Initializes the weights and biases of the layer.\n",
        "        \"\"\"\n",
        "        np.random.seed(42)\n",
        "        self.W = np.random.randn(self.input_shape, self.length)\n",
        "        self.bias = np.zeros((1, self.length))\n",
        "\n",
        "    def set_input_shape(self, num):\n",
        "        \"\"\"\n",
        "        Sets the input shape of the layer.\n",
        "\n",
        "        Parameters:\n",
        "        - num (int): The shape of the input data.\n",
        "        \"\"\"\n",
        "        self.input_shape = num\n",
        "\n",
        "def activation_functions(activation_function, Z):\n",
        "    \"\"\"\n",
        "    Applies the specified activation function to the given input.\n",
        "\n",
        "    Parameters:\n",
        "    activation_function (str): The activation function to apply. Valid options are 'sigmoid' and 'relu'.\n",
        "    Z (numpy.ndarray): The input to the activation function.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: The output of the activation function.\n",
        "    \"\"\"\n",
        "    if activation_function == 'sigmoid':\n",
        "        z = np.clip(Z, -500, 500)\n",
        "        A = 1 / (1 + np.exp(-z))\n",
        "        return A\n",
        "    elif activation_function == 'relu':\n",
        "        A = np.maximum(0, Z)\n",
        "        return A\n",
        "\n",
        "def back_sigmoid(outL):\n",
        "    return outL * (1 - outL)\n",
        "\n",
        "def back_relu(Z):\n",
        "    return np.array(Z > 0, dtype='float')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Iris Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "      <td>0.819232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
              "count         150.000000        150.000000         150.000000   \n",
              "mean            5.843333          3.057333           3.758000   \n",
              "std             0.828066          0.435866           1.765298   \n",
              "min             4.300000          2.000000           1.000000   \n",
              "25%             5.100000          2.800000           1.600000   \n",
              "50%             5.800000          3.000000           4.350000   \n",
              "75%             6.400000          3.300000           5.100000   \n",
              "max             7.900000          4.400000           6.900000   \n",
              "\n",
              "       petal width (cm)      target  \n",
              "count        150.000000  150.000000  \n",
              "mean           1.199333    1.000000  \n",
              "std            0.762238    0.819232  \n",
              "min            0.100000    0.000000  \n",
              "25%            0.300000    0.000000  \n",
              "50%            1.300000    1.000000  \n",
              "75%            1.800000    2.000000  \n",
              "max            2.500000    2.000000  "
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #PLotting the data\n",
        "# sns.pairplot(df, hue='target', palette='Set1')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize the input data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encode the target variable (for multiclass classification)\n",
        "num_classes = len(np.unique(y))\n",
        "y_one_hot = np.eye(num_classes)[y.reshape(-1)]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "input_size = X_train.shape[1]\n",
        "output_size = num_classes\n",
        "\n",
        "# Create the neural network\n",
        "nn = NN()\n",
        "nn.add(Layer(input_shape=input_size, length=8, activation_function='sigmoid'))\n",
        "nn.add(Layer(length=output_size, activation_function='sigmoid'))\n",
        "\n",
        "# Train the neural network\n",
        "epochs = 10000\n",
        "learning_rate = 0.01\n",
        "nn.fit(X_train, y_train, epochs, learning_rate, multiclass=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 100.00%\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "predictions = nn.predict(X_test)\n",
        "\n",
        "# Convert one-hot encoded predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert one-hot encoded true labels to class labels\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a heatmap of the confusion matrix\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Iris  with Sklearn Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Of the custom model: 100.00%\n",
            "Accuracy of sklearn model: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a multi-layer perceptron (MLP) classifier\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the models\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy Of the custom model: {accuracy * 100:.2f}%\")\n",
        "print(f\"Accuracy of sklearn model: {accuracy_sklearn * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Iris  with Keras Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 1s 29ms/step - loss: 1.0324 - accuracy: 0.4074 - val_loss: 0.9150 - val_accuracy: 0.7500\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9684 - accuracy: 0.5000 - val_loss: 0.8812 - val_accuracy: 0.7500\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9107 - accuracy: 0.5926 - val_loss: 0.8493 - val_accuracy: 0.7500\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8569 - accuracy: 0.6944 - val_loss: 0.8186 - val_accuracy: 0.7500\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8077 - accuracy: 0.7407 - val_loss: 0.7898 - val_accuracy: 0.8333\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7639 - accuracy: 0.7870 - val_loss: 0.7628 - val_accuracy: 0.8333\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7228 - accuracy: 0.7963 - val_loss: 0.7389 - val_accuracy: 0.8333\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6853 - accuracy: 0.7963 - val_loss: 0.7159 - val_accuracy: 0.8333\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.6529 - accuracy: 0.7963 - val_loss: 0.6943 - val_accuracy: 0.8333\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6243 - accuracy: 0.7963 - val_loss: 0.6756 - val_accuracy: 0.8333\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5962 - accuracy: 0.7963 - val_loss: 0.6567 - val_accuracy: 0.8333\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.7963 - val_loss: 0.6397 - val_accuracy: 0.8333\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5518 - accuracy: 0.8056 - val_loss: 0.6226 - val_accuracy: 0.8333\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.8148 - val_loss: 0.6079 - val_accuracy: 0.8333\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.8148 - val_loss: 0.5940 - val_accuracy: 0.8333\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.8241 - val_loss: 0.5812 - val_accuracy: 0.8333\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.8241 - val_loss: 0.5703 - val_accuracy: 0.8333\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.8241 - val_loss: 0.5585 - val_accuracy: 0.8333\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.8241 - val_loss: 0.5482 - val_accuracy: 0.8333\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8241 - val_loss: 0.5380 - val_accuracy: 0.8333\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8426 - val_loss: 0.5299 - val_accuracy: 0.9167\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8426 - val_loss: 0.5204 - val_accuracy: 0.9167\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8426 - val_loss: 0.5120 - val_accuracy: 0.9167\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8426 - val_loss: 0.5040 - val_accuracy: 0.9167\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8426 - val_loss: 0.4966 - val_accuracy: 0.9167\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8426 - val_loss: 0.4901 - val_accuracy: 0.9167\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8519 - val_loss: 0.4843 - val_accuracy: 0.9167\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8519 - val_loss: 0.4780 - val_accuracy: 0.9167\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8519 - val_loss: 0.4710 - val_accuracy: 0.9167\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.3682 - accuracy: 0.8519 - val_loss: 0.4650 - val_accuracy: 0.9167\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3622 - accuracy: 0.8519 - val_loss: 0.4587 - val_accuracy: 0.9167\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8519 - val_loss: 0.4544 - val_accuracy: 0.9167\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8519 - val_loss: 0.4486 - val_accuracy: 0.9167\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8519 - val_loss: 0.4434 - val_accuracy: 0.9167\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8611 - val_loss: 0.4402 - val_accuracy: 0.9167\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8704 - val_loss: 0.4344 - val_accuracy: 0.9167\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8704 - val_loss: 0.4290 - val_accuracy: 0.9167\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3257 - accuracy: 0.8704 - val_loss: 0.4260 - val_accuracy: 0.9167\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.8704 - val_loss: 0.4213 - val_accuracy: 0.9167\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3167 - accuracy: 0.8704 - val_loss: 0.4171 - val_accuracy: 0.9167\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3126 - accuracy: 0.8889 - val_loss: 0.4138 - val_accuracy: 0.9167\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3083 - accuracy: 0.8889 - val_loss: 0.4111 - val_accuracy: 0.9167\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.3042 - accuracy: 0.8889 - val_loss: 0.4067 - val_accuracy: 0.9167\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8889 - val_loss: 0.4030 - val_accuracy: 0.9167\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2962 - accuracy: 0.8889 - val_loss: 0.3990 - val_accuracy: 0.9167\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8889 - val_loss: 0.3962 - val_accuracy: 0.9167\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8889 - val_loss: 0.3914 - val_accuracy: 0.9167\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.3885 - val_accuracy: 0.9167\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2819 - accuracy: 0.8981 - val_loss: 0.3862 - val_accuracy: 0.9167\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2783 - accuracy: 0.9074 - val_loss: 0.3819 - val_accuracy: 0.9167\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2750 - accuracy: 0.9074 - val_loss: 0.3793 - val_accuracy: 0.9167\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2714 - accuracy: 0.9074 - val_loss: 0.3765 - val_accuracy: 0.9167\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2685 - accuracy: 0.9074 - val_loss: 0.3720 - val_accuracy: 0.9167\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2649 - accuracy: 0.9167 - val_loss: 0.3695 - val_accuracy: 0.9167\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2620 - accuracy: 0.9167 - val_loss: 0.3674 - val_accuracy: 0.9167\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.9167 - val_loss: 0.3643 - val_accuracy: 0.9167\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2557 - accuracy: 0.9167 - val_loss: 0.3602 - val_accuracy: 0.9167\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9167 - val_loss: 0.3560 - val_accuracy: 0.9167\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2503 - accuracy: 0.9167 - val_loss: 0.3517 - val_accuracy: 0.9167\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.9167 - val_loss: 0.3500 - val_accuracy: 0.9167\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.9167 - val_loss: 0.3459 - val_accuracy: 0.9167\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9259 - val_loss: 0.3461 - val_accuracy: 0.9167\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9259 - val_loss: 0.3412 - val_accuracy: 0.9167\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9259 - val_loss: 0.3411 - val_accuracy: 0.9167\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9259 - val_loss: 0.3369 - val_accuracy: 0.9167\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9259 - val_loss: 0.3334 - val_accuracy: 0.9167\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9259 - val_loss: 0.3310 - val_accuracy: 0.9167\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2256 - accuracy: 0.9259 - val_loss: 0.3281 - val_accuracy: 0.9167\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.9352 - val_loss: 0.3281 - val_accuracy: 0.9167\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2205 - accuracy: 0.9352 - val_loss: 0.3257 - val_accuracy: 0.9167\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9352 - val_loss: 0.3237 - val_accuracy: 0.9167\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9444 - val_loss: 0.3217 - val_accuracy: 0.9167\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2132 - accuracy: 0.9444 - val_loss: 0.3192 - val_accuracy: 0.9167\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2108 - accuracy: 0.9444 - val_loss: 0.3168 - val_accuracy: 0.9167\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 0.9537 - val_loss: 0.3149 - val_accuracy: 0.9167\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9537 - val_loss: 0.3115 - val_accuracy: 0.9167\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2038 - accuracy: 0.9537 - val_loss: 0.3074 - val_accuracy: 0.9167\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9537 - val_loss: 0.3052 - val_accuracy: 0.9167\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9537 - val_loss: 0.3039 - val_accuracy: 0.9167\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1973 - accuracy: 0.9537 - val_loss: 0.3028 - val_accuracy: 0.9167\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.9537 - val_loss: 0.2998 - val_accuracy: 0.9167\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9537 - val_loss: 0.2992 - val_accuracy: 0.9167\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1909 - accuracy: 0.9537 - val_loss: 0.2964 - val_accuracy: 0.9167\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9537 - val_loss: 0.2933 - val_accuracy: 0.9167\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1869 - accuracy: 0.9537 - val_loss: 0.2941 - val_accuracy: 0.9167\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1847 - accuracy: 0.9537 - val_loss: 0.2921 - val_accuracy: 0.9167\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9630 - val_loss: 0.2907 - val_accuracy: 0.9167\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9537 - val_loss: 0.2873 - val_accuracy: 0.9167\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9630 - val_loss: 0.2867 - val_accuracy: 0.9167\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9630 - val_loss: 0.2823 - val_accuracy: 0.9167\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.9630 - val_loss: 0.2820 - val_accuracy: 0.9167\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1735 - accuracy: 0.9630 - val_loss: 0.2818 - val_accuracy: 0.9167\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9630 - val_loss: 0.2780 - val_accuracy: 0.9167\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.9630 - val_loss: 0.2768 - val_accuracy: 0.9167\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1679 - accuracy: 0.9630 - val_loss: 0.2757 - val_accuracy: 0.9167\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.9630 - val_loss: 0.2735 - val_accuracy: 0.9167\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9630 - val_loss: 0.2737 - val_accuracy: 0.9167\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1627 - accuracy: 0.9630 - val_loss: 0.2708 - val_accuracy: 0.9167\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1611 - accuracy: 0.9630 - val_loss: 0.2703 - val_accuracy: 0.9167\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1594 - accuracy: 0.9630 - val_loss: 0.2696 - val_accuracy: 0.9167\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1577 - accuracy: 0.9722 - val_loss: 0.2683 - val_accuracy: 0.9167\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.9630 - val_loss: 0.2682 - val_accuracy: 0.9167\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9722 - val_loss: 0.2665 - val_accuracy: 0.9167\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9722 - val_loss: 0.2660 - val_accuracy: 0.9167\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1513 - accuracy: 0.9722 - val_loss: 0.2631 - val_accuracy: 0.9167\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1498 - accuracy: 0.9722 - val_loss: 0.2621 - val_accuracy: 0.9167\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 0.9722 - val_loss: 0.2602 - val_accuracy: 0.9167\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9722 - val_loss: 0.2601 - val_accuracy: 0.9167\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1453 - accuracy: 0.9722 - val_loss: 0.2581 - val_accuracy: 0.9167\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1438 - accuracy: 0.9722 - val_loss: 0.2569 - val_accuracy: 0.9167\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.9722 - val_loss: 0.2531 - val_accuracy: 0.9167\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9722 - val_loss: 0.2530 - val_accuracy: 0.9167\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1396 - accuracy: 0.9722 - val_loss: 0.2515 - val_accuracy: 0.9167\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1384 - accuracy: 0.9722 - val_loss: 0.2516 - val_accuracy: 0.9167\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1369 - accuracy: 0.9722 - val_loss: 0.2513 - val_accuracy: 0.9167\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9722 - val_loss: 0.2479 - val_accuracy: 0.9167\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1344 - accuracy: 0.9722 - val_loss: 0.2485 - val_accuracy: 0.9167\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1331 - accuracy: 0.9722 - val_loss: 0.2467 - val_accuracy: 0.9167\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1321 - accuracy: 0.9722 - val_loss: 0.2475 - val_accuracy: 0.9167\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9722 - val_loss: 0.2454 - val_accuracy: 0.9167\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1295 - accuracy: 0.9722 - val_loss: 0.2427 - val_accuracy: 0.9167\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9722 - val_loss: 0.2407 - val_accuracy: 0.9167\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1273 - accuracy: 0.9722 - val_loss: 0.2404 - val_accuracy: 0.9167\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1264 - accuracy: 0.9722 - val_loss: 0.2408 - val_accuracy: 0.9167\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9722 - val_loss: 0.2381 - val_accuracy: 0.9167\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1240 - accuracy: 0.9630 - val_loss: 0.2364 - val_accuracy: 0.9167\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9630 - val_loss: 0.2331 - val_accuracy: 0.9167\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9630 - val_loss: 0.2356 - val_accuracy: 0.9167\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9630 - val_loss: 0.2336 - val_accuracy: 0.9167\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.9722 - val_loss: 0.2327 - val_accuracy: 0.9167\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.9630 - val_loss: 0.2350 - val_accuracy: 0.9167\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9630 - val_loss: 0.2286 - val_accuracy: 0.9167\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9630 - val_loss: 0.2288 - val_accuracy: 0.9167\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9630 - val_loss: 0.2302 - val_accuracy: 0.9167\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9630 - val_loss: 0.2261 - val_accuracy: 0.9167\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9630 - val_loss: 0.2270 - val_accuracy: 0.9167\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9630 - val_loss: 0.2247 - val_accuracy: 0.9167\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1124 - accuracy: 0.9722 - val_loss: 0.2235 - val_accuracy: 0.9167\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1122 - accuracy: 0.9722 - val_loss: 0.2290 - val_accuracy: 0.9167\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.9815 - val_loss: 0.2270 - val_accuracy: 0.9167\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1100 - accuracy: 0.9722 - val_loss: 0.2220 - val_accuracy: 0.9167\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9722 - val_loss: 0.2227 - val_accuracy: 0.9167\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9815 - val_loss: 0.2252 - val_accuracy: 0.9167\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9722 - val_loss: 0.2161 - val_accuracy: 0.9167\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9722 - val_loss: 0.2154 - val_accuracy: 0.9167\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1063 - accuracy: 0.9722 - val_loss: 0.2204 - val_accuracy: 0.9167\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9722 - val_loss: 0.2202 - val_accuracy: 0.9167\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9722 - val_loss: 0.2186 - val_accuracy: 0.9167\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1039 - accuracy: 0.9722 - val_loss: 0.2144 - val_accuracy: 0.9167\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9722 - val_loss: 0.2145 - val_accuracy: 0.9167\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1028 - accuracy: 0.9722 - val_loss: 0.2119 - val_accuracy: 0.9167\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 0.9722 - val_loss: 0.2141 - val_accuracy: 0.9167\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9722 - val_loss: 0.2154 - val_accuracy: 0.9167\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.9722 - val_loss: 0.2140 - val_accuracy: 0.9167\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.9722 - val_loss: 0.2127 - val_accuracy: 0.9167\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0990 - accuracy: 0.9722 - val_loss: 0.2114 - val_accuracy: 0.9167\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9722 - val_loss: 0.2134 - val_accuracy: 0.9167\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0981 - accuracy: 0.9815 - val_loss: 0.2158 - val_accuracy: 0.9167\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9815 - val_loss: 0.2123 - val_accuracy: 0.9167\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9722 - val_loss: 0.2055 - val_accuracy: 0.9167\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0963 - accuracy: 0.9722 - val_loss: 0.2101 - val_accuracy: 0.9167\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9722 - val_loss: 0.2095 - val_accuracy: 0.9167\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9722 - val_loss: 0.2112 - val_accuracy: 0.9167\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9815 - val_loss: 0.2079 - val_accuracy: 0.9167\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9722 - val_loss: 0.2046 - val_accuracy: 0.9167\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0933 - accuracy: 0.9722 - val_loss: 0.2043 - val_accuracy: 0.9167\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0927 - accuracy: 0.9722 - val_loss: 0.2030 - val_accuracy: 0.9167\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9722 - val_loss: 0.2020 - val_accuracy: 0.9167\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9722 - val_loss: 0.2001 - val_accuracy: 0.9167\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9722 - val_loss: 0.2009 - val_accuracy: 0.9167\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9722 - val_loss: 0.2039 - val_accuracy: 0.9167\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9722 - val_loss: 0.2081 - val_accuracy: 0.9167\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9722 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9722 - val_loss: 0.2017 - val_accuracy: 0.9167\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9722 - val_loss: 0.2020 - val_accuracy: 0.9167\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.2002 - val_accuracy: 0.9167\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0879 - accuracy: 0.9722 - val_loss: 0.1992 - val_accuracy: 0.9167\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9722 - val_loss: 0.1990 - val_accuracy: 0.9167\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 0.1981 - val_accuracy: 0.9167\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9722 - val_loss: 0.1949 - val_accuracy: 0.9167\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.9722 - val_loss: 0.1973 - val_accuracy: 0.9167\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9722 - val_loss: 0.1983 - val_accuracy: 0.9167\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9722 - val_loss: 0.1975 - val_accuracy: 0.9167\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0849 - accuracy: 0.9722 - val_loss: 0.1947 - val_accuracy: 0.9167\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9722 - val_loss: 0.1925 - val_accuracy: 0.9167\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 0.9722 - val_loss: 0.1929 - val_accuracy: 0.9167\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.1978 - val_accuracy: 0.9167\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9722 - val_loss: 0.1963 - val_accuracy: 0.9167\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9722 - val_loss: 0.1983 - val_accuracy: 0.9167\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9722 - val_loss: 0.1947 - val_accuracy: 0.9167\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9722 - val_loss: 0.1969 - val_accuracy: 0.9167\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9722 - val_loss: 0.1980 - val_accuracy: 0.9167\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9722 - val_loss: 0.1953 - val_accuracy: 0.9167\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.1966 - val_accuracy: 0.9167\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 0.1968 - val_accuracy: 0.9167\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9722 - val_loss: 0.1929 - val_accuracy: 0.9167\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9722 - val_loss: 0.1953 - val_accuracy: 0.9167\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9630 - val_loss: 0.1973 - val_accuracy: 0.9167\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9722 - val_loss: 0.1947 - val_accuracy: 0.9167\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0791 - accuracy: 0.9722 - val_loss: 0.2007 - val_accuracy: 0.9167\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9722 - val_loss: 0.1978 - val_accuracy: 0.9167\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 0.9722 - val_loss: 0.1994 - val_accuracy: 0.9167\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9722 - val_loss: 0.2046 - val_accuracy: 0.9167\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9630 - val_loss: 0.2077 - val_accuracy: 0.9167\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9630 - val_loss: 0.2061 - val_accuracy: 0.9167\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9722 - val_loss: 0.2036 - val_accuracy: 0.9167\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9722 - val_loss: 0.2039 - val_accuracy: 0.9167\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9722 - val_loss: 0.2060 - val_accuracy: 0.9167\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0755 - accuracy: 0.9722 - val_loss: 0.2068 - val_accuracy: 0.9167\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9722 - val_loss: 0.2067 - val_accuracy: 0.9167\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9722 - val_loss: 0.2044 - val_accuracy: 0.9167\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9722 - val_loss: 0.2038 - val_accuracy: 0.9167\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9722 - val_loss: 0.2074 - val_accuracy: 0.9167\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9722 - val_loss: 0.2047 - val_accuracy: 0.9167\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9722 - val_loss: 0.2075 - val_accuracy: 0.9167\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9722 - val_loss: 0.2054 - val_accuracy: 0.9167\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 0.2021 - val_accuracy: 0.9167\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0730 - accuracy: 0.9722 - val_loss: 0.2071 - val_accuracy: 0.9167\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9630 - val_loss: 0.2103 - val_accuracy: 0.9167\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9722 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9722 - val_loss: 0.2068 - val_accuracy: 0.9167\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9722 - val_loss: 0.2042 - val_accuracy: 0.9167\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9722 - val_loss: 0.2053 - val_accuracy: 0.9167\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9630 - val_loss: 0.2079 - val_accuracy: 0.9167\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9630 - val_loss: 0.2076 - val_accuracy: 0.9167\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9722 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.2027 - val_accuracy: 0.9167\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9722 - val_loss: 0.2009 - val_accuracy: 0.9167\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.2072 - val_accuracy: 0.9167\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0705 - accuracy: 0.9630 - val_loss: 0.2024 - val_accuracy: 0.9167\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0700 - accuracy: 0.9722 - val_loss: 0.2030 - val_accuracy: 0.9167\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9722 - val_loss: 0.2051 - val_accuracy: 0.9167\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9722 - val_loss: 0.2045 - val_accuracy: 0.9167\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9722 - val_loss: 0.2038 - val_accuracy: 0.9167\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0698 - accuracy: 0.9630 - val_loss: 0.2080 - val_accuracy: 0.9167\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 0.9630 - val_loss: 0.2052 - val_accuracy: 0.9167\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9722 - val_loss: 0.2029 - val_accuracy: 0.9167\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9722 - val_loss: 0.2052 - val_accuracy: 0.9167\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9722 - val_loss: 0.2030 - val_accuracy: 0.9167\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9722 - val_loss: 0.1992 - val_accuracy: 0.9167\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9722 - val_loss: 0.2020 - val_accuracy: 0.9167\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9722 - val_loss: 0.2024 - val_accuracy: 0.9167\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9630 - val_loss: 0.2031 - val_accuracy: 0.9167\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9722 - val_loss: 0.2002 - val_accuracy: 0.9167\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9722 - val_loss: 0.2011 - val_accuracy: 0.9167\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9630 - val_loss: 0.2028 - val_accuracy: 0.9167\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9630 - val_loss: 0.2045 - val_accuracy: 0.9167\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9630 - val_loss: 0.2057 - val_accuracy: 0.9167\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9630 - val_loss: 0.2047 - val_accuracy: 0.9167\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9630 - val_loss: 0.2036 - val_accuracy: 0.9167\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9630 - val_loss: 0.1971 - val_accuracy: 0.9167\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9722 - val_loss: 0.1982 - val_accuracy: 0.9167\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9722 - val_loss: 0.1934 - val_accuracy: 0.9167\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9722 - val_loss: 0.1997 - val_accuracy: 0.9167\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9630 - val_loss: 0.2026 - val_accuracy: 0.9167\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9630 - val_loss: 0.2017 - val_accuracy: 0.9167\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9630 - val_loss: 0.2020 - val_accuracy: 0.9167\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9630 - val_loss: 0.1984 - val_accuracy: 0.9167\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9630 - val_loss: 0.2030 - val_accuracy: 0.9167\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9630 - val_loss: 0.2012 - val_accuracy: 0.9167\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9630 - val_loss: 0.2012 - val_accuracy: 0.9167\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9630 - val_loss: 0.1980 - val_accuracy: 0.9167\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0646 - accuracy: 0.9722 - val_loss: 0.1956 - val_accuracy: 0.9167\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0651 - accuracy: 0.9630 - val_loss: 0.2002 - val_accuracy: 0.9167\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9630 - val_loss: 0.1963 - val_accuracy: 0.9167\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.9630 - val_loss: 0.1964 - val_accuracy: 0.9167\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9630 - val_loss: 0.1908 - val_accuracy: 0.9167\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9722 - val_loss: 0.1873 - val_accuracy: 0.9167\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9630 - val_loss: 0.1977 - val_accuracy: 0.9167\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9630 - val_loss: 0.1969 - val_accuracy: 0.9167\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0634 - accuracy: 0.9630 - val_loss: 0.1954 - val_accuracy: 0.9167\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9630 - val_loss: 0.1892 - val_accuracy: 0.9167\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9630 - val_loss: 0.1928 - val_accuracy: 0.9167\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9630 - val_loss: 0.1959 - val_accuracy: 0.9167\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0634 - accuracy: 0.9630 - val_loss: 0.1880 - val_accuracy: 0.9167\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0628 - accuracy: 0.9722 - val_loss: 0.1880 - val_accuracy: 0.9167\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.9630 - val_loss: 0.1948 - val_accuracy: 0.9167\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9630 - val_loss: 0.1924 - val_accuracy: 0.9167\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9630 - val_loss: 0.1895 - val_accuracy: 0.9167\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9630 - val_loss: 0.1854 - val_accuracy: 0.9167\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9630 - val_loss: 0.1881 - val_accuracy: 0.9167\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9630 - val_loss: 0.1863 - val_accuracy: 0.9167\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9722 - val_loss: 0.1830 - val_accuracy: 0.9167\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9722 - val_loss: 0.1914 - val_accuracy: 0.9167\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9630 - val_loss: 0.1877 - val_accuracy: 0.9167\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9630 - val_loss: 0.1909 - val_accuracy: 0.9167\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9630 - val_loss: 0.1837 - val_accuracy: 0.9167\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9630 - val_loss: 0.1835 - val_accuracy: 0.9167\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9630 - val_loss: 0.1844 - val_accuracy: 0.9167\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9722 - val_loss: 0.1825 - val_accuracy: 0.9167\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9722 - val_loss: 0.1817 - val_accuracy: 0.9167\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9630 - val_loss: 0.1849 - val_accuracy: 0.9167\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0605 - accuracy: 0.9630 - val_loss: 0.1872 - val_accuracy: 0.9167\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9630 - val_loss: 0.1859 - val_accuracy: 0.9167\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9630 - val_loss: 0.1891 - val_accuracy: 0.9167\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9630 - val_loss: 0.1847 - val_accuracy: 0.9167\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9630 - val_loss: 0.1871 - val_accuracy: 0.9167\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9630 - val_loss: 0.1818 - val_accuracy: 0.9167\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9630 - val_loss: 0.1828 - val_accuracy: 0.9167\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9630 - val_loss: 0.1927 - val_accuracy: 0.9167\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9630 - val_loss: 0.1838 - val_accuracy: 0.9167\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9630 - val_loss: 0.1844 - val_accuracy: 0.9167\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9630 - val_loss: 0.1826 - val_accuracy: 0.9167\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9630 - val_loss: 0.1821 - val_accuracy: 0.9167\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9630 - val_loss: 0.1818 - val_accuracy: 0.9167\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9630 - val_loss: 0.1771 - val_accuracy: 0.9167\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0593 - accuracy: 0.9630 - val_loss: 0.1761 - val_accuracy: 0.9167\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9722 - val_loss: 0.1770 - val_accuracy: 0.9167\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9630 - val_loss: 0.1825 - val_accuracy: 0.9167\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9630 - val_loss: 0.1851 - val_accuracy: 0.9167\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9722 - val_loss: 0.1823 - val_accuracy: 0.9167\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9722 - val_loss: 0.1823 - val_accuracy: 0.9167\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9630 - val_loss: 0.1803 - val_accuracy: 0.9167\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9630 - val_loss: 0.1748 - val_accuracy: 0.9167\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9630 - val_loss: 0.1766 - val_accuracy: 0.9167\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9722 - val_loss: 0.1816 - val_accuracy: 0.9167\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9630 - val_loss: 0.1760 - val_accuracy: 0.9167\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 0.9630 - val_loss: 0.1786 - val_accuracy: 0.9167\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9722 - val_loss: 0.1815 - val_accuracy: 0.9167\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9722 - val_loss: 0.1809 - val_accuracy: 0.9167\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9630 - val_loss: 0.1749 - val_accuracy: 0.9167\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0576 - accuracy: 0.9630 - val_loss: 0.1778 - val_accuracy: 0.9167\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0578 - accuracy: 0.9630 - val_loss: 0.1793 - val_accuracy: 0.9167\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9722 - val_loss: 0.1791 - val_accuracy: 0.9167\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9722 - val_loss: 0.1819 - val_accuracy: 0.9167\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9722 - val_loss: 0.1779 - val_accuracy: 0.9167\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9722 - val_loss: 0.1800 - val_accuracy: 0.9167\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9722 - val_loss: 0.1818 - val_accuracy: 0.9167\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9722 - val_loss: 0.1798 - val_accuracy: 0.9167\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9722 - val_loss: 0.1732 - val_accuracy: 0.9167\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9722 - val_loss: 0.1790 - val_accuracy: 0.9167\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9722 - val_loss: 0.1788 - val_accuracy: 0.9167\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9722 - val_loss: 0.1734 - val_accuracy: 0.9167\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9722 - val_loss: 0.1776 - val_accuracy: 0.9167\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9722 - val_loss: 0.1741 - val_accuracy: 0.9167\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9722 - val_loss: 0.1741 - val_accuracy: 0.9167\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9630 - val_loss: 0.1732 - val_accuracy: 0.9167\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9630 - val_loss: 0.1723 - val_accuracy: 0.9167\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9630 - val_loss: 0.1714 - val_accuracy: 0.9167\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9630 - val_loss: 0.1715 - val_accuracy: 0.9167\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.1714 - val_accuracy: 0.9167\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.1726 - val_accuracy: 0.9167\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9722 - val_loss: 0.1722 - val_accuracy: 0.9167\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9722 - val_loss: 0.1687 - val_accuracy: 0.9167\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9722 - val_loss: 0.1750 - val_accuracy: 0.9167\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9722 - val_loss: 0.1701 - val_accuracy: 0.9167\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9722 - val_loss: 0.1710 - val_accuracy: 0.9167\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9722 - val_loss: 0.1721 - val_accuracy: 0.9167\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9722 - val_loss: 0.1698 - val_accuracy: 0.9167\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9722 - val_loss: 0.1701 - val_accuracy: 0.9167\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0553 - accuracy: 0.9722 - val_loss: 0.1725 - val_accuracy: 0.9167\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9722 - val_loss: 0.1745 - val_accuracy: 0.9167\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 0.9722 - val_loss: 0.1739 - val_accuracy: 0.9167\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9722 - val_loss: 0.1733 - val_accuracy: 0.9167\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9722 - val_loss: 0.1680 - val_accuracy: 0.9167\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9722 - val_loss: 0.1655 - val_accuracy: 0.9167\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9722 - val_loss: 0.1644 - val_accuracy: 0.9167\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9722 - val_loss: 0.1675 - val_accuracy: 0.9167\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9722 - val_loss: 0.1647 - val_accuracy: 0.9167\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9722 - val_loss: 0.1701 - val_accuracy: 0.9167\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9722 - val_loss: 0.1671 - val_accuracy: 0.9167\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9722 - val_loss: 0.1691 - val_accuracy: 0.9167\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9722 - val_loss: 0.1695 - val_accuracy: 0.9167\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 0.9722 - val_loss: 0.1694 - val_accuracy: 0.9167\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9722 - val_loss: 0.1649 - val_accuracy: 0.9167\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9722 - val_loss: 0.1679 - val_accuracy: 0.9167\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9722 - val_loss: 0.1708 - val_accuracy: 0.9167\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9722 - val_loss: 0.1721 - val_accuracy: 0.9167\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9722 - val_loss: 0.1673 - val_accuracy: 0.9167\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9722 - val_loss: 0.1736 - val_accuracy: 0.9167\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9722 - val_loss: 0.1703 - val_accuracy: 0.9167\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9722 - val_loss: 0.1748 - val_accuracy: 0.9167\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9815 - val_loss: 0.1730 - val_accuracy: 0.9167\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9722 - val_loss: 0.1717 - val_accuracy: 0.9167\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9722 - val_loss: 0.1640 - val_accuracy: 0.9167\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9722 - val_loss: 0.1673 - val_accuracy: 0.9167\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9722 - val_loss: 0.1679 - val_accuracy: 0.9167\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9722 - val_loss: 0.1740 - val_accuracy: 0.9167\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9722 - val_loss: 0.1709 - val_accuracy: 0.9167\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9722 - val_loss: 0.1674 - val_accuracy: 0.9167\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9722 - val_loss: 0.1685 - val_accuracy: 0.9167\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0531 - accuracy: 0.9722 - val_loss: 0.1689 - val_accuracy: 0.9167\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9722 - val_loss: 0.1683 - val_accuracy: 0.9167\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9722 - val_loss: 0.1711 - val_accuracy: 0.9167\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.1743 - val_accuracy: 0.9167\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.1748 - val_accuracy: 0.9167\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9722 - val_loss: 0.1679 - val_accuracy: 0.9167\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9722 - val_loss: 0.1683 - val_accuracy: 0.9167\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9722 - val_loss: 0.1656 - val_accuracy: 0.9167\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9722 - val_loss: 0.1646 - val_accuracy: 0.9167\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9722 - val_loss: 0.1681 - val_accuracy: 0.9167\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9722 - val_loss: 0.1746 - val_accuracy: 0.9167\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.1749 - val_accuracy: 0.9167\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.1732 - val_accuracy: 0.9167\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0525 - accuracy: 0.9722 - val_loss: 0.1689 - val_accuracy: 0.9167\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9722 - val_loss: 0.1670 - val_accuracy: 0.9167\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9722 - val_loss: 0.1724 - val_accuracy: 0.9167\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9722 - val_loss: 0.1687 - val_accuracy: 0.9167\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9722 - val_loss: 0.1716 - val_accuracy: 0.9167\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9722 - val_loss: 0.1702 - val_accuracy: 0.9167\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0523 - accuracy: 0.9722 - val_loss: 0.1748 - val_accuracy: 0.9167\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0519 - accuracy: 0.9722 - val_loss: 0.1726 - val_accuracy: 0.9167\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9722 - val_loss: 0.1718 - val_accuracy: 0.9167\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9722 - val_loss: 0.1725 - val_accuracy: 0.9167\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9815 - val_loss: 0.1751 - val_accuracy: 0.9167\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9722 - val_loss: 0.1730 - val_accuracy: 0.9167\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9722 - val_loss: 0.1718 - val_accuracy: 0.9167\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9722 - val_loss: 0.1690 - val_accuracy: 0.9167\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9722 - val_loss: 0.1679 - val_accuracy: 0.9167\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9722 - val_loss: 0.1662 - val_accuracy: 0.9167\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9722 - val_loss: 0.1743 - val_accuracy: 0.9167\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.1762 - val_accuracy: 0.9167\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9815 - val_loss: 0.1714 - val_accuracy: 0.9167\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9722 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9722 - val_loss: 0.1737 - val_accuracy: 0.9167\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9722 - val_loss: 0.1704 - val_accuracy: 0.9167\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9722 - val_loss: 0.1695 - val_accuracy: 0.9167\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9722 - val_loss: 0.1700 - val_accuracy: 0.9167\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9722 - val_loss: 0.1684 - val_accuracy: 0.9167\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9722 - val_loss: 0.1704 - val_accuracy: 0.9167\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9722 - val_loss: 0.1708 - val_accuracy: 0.9167\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9815 - val_loss: 0.1737 - val_accuracy: 0.9167\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9722 - val_loss: 0.1719 - val_accuracy: 0.9167\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9722 - val_loss: 0.1726 - val_accuracy: 0.9167\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9722 - val_loss: 0.1734 - val_accuracy: 0.9167\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9722 - val_loss: 0.1715 - val_accuracy: 0.9167\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0507 - accuracy: 0.9722 - val_loss: 0.1694 - val_accuracy: 0.9167\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9722 - val_loss: 0.1691 - val_accuracy: 0.9167\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9722 - val_loss: 0.1677 - val_accuracy: 0.9167\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9722 - val_loss: 0.1696 - val_accuracy: 0.9167\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0505 - accuracy: 0.9722 - val_loss: 0.1674 - val_accuracy: 0.9167\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9722 - val_loss: 0.1672 - val_accuracy: 0.9167\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9722 - val_loss: 0.1668 - val_accuracy: 0.9167\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9722 - val_loss: 0.1685 - val_accuracy: 0.9167\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9722 - val_loss: 0.1663 - val_accuracy: 0.9167\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9722 - val_loss: 0.1719 - val_accuracy: 0.9167\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 0.1722 - val_accuracy: 0.9167\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9722 - val_loss: 0.1736 - val_accuracy: 0.9167\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9722 - val_loss: 0.1723 - val_accuracy: 0.9167\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9722 - val_loss: 0.1730 - val_accuracy: 0.9167\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 0.1745 - val_accuracy: 0.9167\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9722 - val_loss: 0.1743 - val_accuracy: 0.9167\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9722 - val_loss: 0.1717 - val_accuracy: 0.9167\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9722 - val_loss: 0.1721 - val_accuracy: 0.9167\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9722 - val_loss: 0.1700 - val_accuracy: 0.9167\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9722 - val_loss: 0.1672 - val_accuracy: 0.9167\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9722 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0499 - accuracy: 0.9722 - val_loss: 0.1716 - val_accuracy: 0.9167\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9722 - val_loss: 0.1666 - val_accuracy: 0.9167\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9722 - val_loss: 0.1676 - val_accuracy: 0.9167\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0497 - accuracy: 0.9722 - val_loss: 0.1711 - val_accuracy: 0.9167\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9722 - val_loss: 0.1703 - val_accuracy: 0.9167\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9722 - val_loss: 0.1753 - val_accuracy: 0.9167\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.1760 - val_accuracy: 0.9167\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9722 - val_loss: 0.1696 - val_accuracy: 0.9167\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9722 - val_loss: 0.1690 - val_accuracy: 0.9167\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9722 - val_loss: 0.1647 - val_accuracy: 0.9167\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9722 - val_loss: 0.1716 - val_accuracy: 0.9167\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.1711 - val_accuracy: 0.9167\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9722 - val_loss: 0.1723 - val_accuracy: 0.9167\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9722 - val_loss: 0.1689 - val_accuracy: 0.9167\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9722 - val_loss: 0.1699 - val_accuracy: 0.9167\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9722 - val_loss: 0.1733 - val_accuracy: 0.9167\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0492 - accuracy: 0.9722 - val_loss: 0.1719 - val_accuracy: 0.9167\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9722 - val_loss: 0.1706 - val_accuracy: 0.9167\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9722 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9722 - val_loss: 0.1718 - val_accuracy: 0.9167\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9722 - val_loss: 0.1736 - val_accuracy: 0.9167\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9815 - val_loss: 0.1736 - val_accuracy: 0.9167\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9722 - val_loss: 0.1754 - val_accuracy: 0.9167\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9815 - val_loss: 0.1796 - val_accuracy: 0.9167\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.9815 - val_loss: 0.1739 - val_accuracy: 0.9167\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9722 - val_loss: 0.1706 - val_accuracy: 0.9167\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9722 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9722 - val_loss: 0.1709 - val_accuracy: 0.9167\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9722 - val_loss: 0.1707 - val_accuracy: 0.9167\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9722 - val_loss: 0.1763 - val_accuracy: 0.9167\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 0.1770 - val_accuracy: 0.9167\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9815 - val_loss: 0.1762 - val_accuracy: 0.9167\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1792 - val_accuracy: 0.9167\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9722 - val_loss: 0.1750 - val_accuracy: 0.9167\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9722 - val_loss: 0.1751 - val_accuracy: 0.9167\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9722 - val_loss: 0.1786 - val_accuracy: 0.9167\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9722 - val_loss: 0.1788 - val_accuracy: 0.9167\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1731 - val_accuracy: 0.9167\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9722 - val_loss: 0.1742 - val_accuracy: 0.9167\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9722 - val_loss: 0.1799 - val_accuracy: 0.9167\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1741 - val_accuracy: 0.9167\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0486 - accuracy: 0.9722 - val_loss: 0.1736 - val_accuracy: 0.9167\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9722 - val_loss: 0.1828 - val_accuracy: 0.9167\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.1788 - val_accuracy: 0.9167\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.1810 - val_accuracy: 0.9167\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9815 - val_loss: 0.1846 - val_accuracy: 0.9167\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.1822 - val_accuracy: 0.9167\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0485 - accuracy: 0.9722 - val_loss: 0.1841 - val_accuracy: 0.9167\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.1779 - val_accuracy: 0.9167\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9722 - val_loss: 0.1796 - val_accuracy: 0.9167\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9722 - val_loss: 0.1756 - val_accuracy: 0.9167\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9722 - val_loss: 0.1826 - val_accuracy: 0.9167\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9815 - val_loss: 0.1860 - val_accuracy: 0.9167\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Accuracy Of the custom model: 100.00%\n",
            "Test Accuracyof the keras model: 100.00%\n"
          ]
        }
      ],
      "source": [
        "#implementing the neural network using keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_one_hot = to_categorical(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=500, batch_size=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy_keras = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Accuracy Of the custom model: {accuracy * 100:.2f}%\")\n",
        "print(f\"Test Accuracyof the keras model: {accuracy_keras * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('mnist_train_small.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19999, 10)"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x = train_df.drop(columns='6').to_numpy()\n",
        "train_y = train_df['6'].to_numpy()\n",
        "train_y = to_categorical(train_y, 10)\n",
        "train_y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = (x_train.reshape(x_train.shape[0], -1) / 255.0)  # Flatten and normalize\n",
        "x_test = (x_test.reshape(x_test.shape[0], -1) / 255.0)\n",
        "y_train = to_categorical(y_train, 10)  # Convert labels to one-hot encoded\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MNN = NN()\n",
        "x =Layer(784,8,'sigmoid')\n",
        "y = Layer(None,10,'sigmoid')\n",
        "MNN.add(x)\n",
        "MNN.add(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "MNN.fit(train_x,train_y,1000,0.001,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8142407120356018"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = MNN.predict(train_x)\n",
        "binary_predictions = np.zeros_like(predictions)\n",
        "binary_predictions[np.arange(len(predictions)), predictions.argmax(axis=1)] = 1\n",
        "\n",
        "\n",
        "np.argmax(binary_predictions,1)\n",
        "np.argmax(train_y,1)\n",
        "accuracy_score(np.argmax(binary_predictions,1),np.argmax(train_y,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 937    0    8    9    3    0    7    2    8    6]\n",
            " [   3 1095    4    7    1    3    0    0   21    1]\n",
            " [  19   12  906   17   11    5   16   17   13   16]\n",
            " [  39    1   30  845    1   19    2   15   19   39]\n",
            " [   1    0    3    0  823    0   12    3   16  124]\n",
            " [  51    2    3  606    9   85   17   10   68   41]\n",
            " [  52    3   13    8   26   12  815    0   28    1]\n",
            " [   1    9   40    1    7    0    1  910    5   54]\n",
            " [  13    5    8   57    6    5   13    4  825   38]\n",
            " [  14    1    1   15   16    1    0   24    5  932]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Make predictions on the test set\n",
        "predictions = MNN.predict(x_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Create a heatmap of the confusion matrix\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Morshedy\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the sklearn model: 97.44%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = datasets.fetch_openml('mnist_784')\n",
        "X = mnist.data.astype('float32') / 255.0\n",
        "y = mnist.target.astype('int')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an MLP classifier\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the sklearn model: {accuracy_sklearn * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Morshedy\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1575/1575 [==============================] - 7s 4ms/step - loss: 0.2847 - accuracy: 0.9189 - val_loss: 0.1553 - val_accuracy: 0.9557\n",
            "Epoch 2/10\n",
            "1575/1575 [==============================] - 5s 3ms/step - loss: 0.1248 - accuracy: 0.9633 - val_loss: 0.1089 - val_accuracy: 0.9684\n",
            "Epoch 3/10\n",
            "1575/1575 [==============================] - 7s 4ms/step - loss: 0.0852 - accuracy: 0.9743 - val_loss: 0.0939 - val_accuracy: 0.9700\n",
            "Epoch 4/10\n",
            "1575/1575 [==============================] - 7s 4ms/step - loss: 0.0635 - accuracy: 0.9806 - val_loss: 0.0878 - val_accuracy: 0.9736\n",
            "Epoch 5/10\n",
            "1575/1575 [==============================] - 7s 4ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0799 - val_accuracy: 0.9755\n",
            "Epoch 6/10\n",
            "1575/1575 [==============================] - 6s 4ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 0.0742 - val_accuracy: 0.9779\n",
            "Epoch 7/10\n",
            "1575/1575 [==============================] - 5s 3ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0761 - val_accuracy: 0.9775\n",
            "Epoch 8/10\n",
            "1575/1575 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0884 - val_accuracy: 0.9745\n",
            "Epoch 9/10\n",
            "1575/1575 [==============================] - 6s 4ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0825 - val_accuracy: 0.9786\n",
            "Epoch 10/10\n",
            "1575/1575 [==============================] - 6s 4ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0891 - val_accuracy: 0.9768\n",
            "438/438 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9741\n",
            "Test Accuracy of the Keras model: 97.41%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = datasets.fetch_openml('mnist_784')\n",
        "X = mnist.data.astype('float32') / 255.0\n",
        "y = mnist.target.astype('int')\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_one_hot = to_categorical(y)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=784, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy_Keras = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy of the Keras model: {accuracy_Keras * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
